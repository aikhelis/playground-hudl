# playground-hudl

This repository is created as personal practice and refreshments on Playwright. It contains some e2e tests for Hudl.com website, which I highly admire. 

## Running tests on GitHub
[GHA workflow](https://github.com/aikhelis/playground-hudl/actions/workflows/playwright.yml) for playwright tests does the following:
- is trigerred on push to main and can be kicked off manually
- injects base url and user creds from GH repository environment variables and secrets
- runs tests against Production
- runs tests in a single headless browser
- saves html report and trace assets on every run with several days of artifact retention

To view the report and go through test execution in Playwright's [Trace viewer](https://playwright.dev/docs/trace-viewer):
- Navigate to a particular run's details
- Download `playwright-report` archive from the bottom of the page
- Unpack and open `index.html`
- Go to https://trace.playwright.dev/ and upload the trace blob file `playwright-report/data/<session-id>.zip`

## Running Tests Locally
```shell
# Install Dependencies
npm install

# Configure Environment Variables
# Copy .env.local.example to .env.local and update the values as needed
cp .env.local.example .env.local

# To run tests locally in headless mode:
npx playwright test

# To debug tests locally:
npx playwright test --ui

# Alternatively, check package.json for any customized command.
```

If tests fail, verify that you have the correct environment variables and configuration settings.

## Test Coverage

_This report aids to illustrate the thought process behind test design. It's auto-generated by co-polit analyzing the current tests folder and file structure and naming conventions. Ensure it remains updated as tests evolve or switch to more fit-for-purpose coverage tool._

### Authn & Authz

| Category          | Scenario                                           | Automated |
|-------------------|----------------------------------------------------|-----------|
| Happy-path        | Successful login and logout with valid credentials | ✅        |
|                   | Successful login with Edit Username step           | ✅        |
| Form validation   | Empty username/password                            | ✅        |
|                   | Invalid email format                               | ✅        |
|                   | Non-existing username                              | ✅        |
|                   | Wrong password                                     | ✅        |
| Web form security | SQL Injection attempt in username field            | ![Pending](https://img.icons8.com/material-outlined/24/000000/unchecked-checkbox.png) |
|                   | XSS attempt in username field                      | ![Pending](https://img.icons8.com/material-outlined/24/000000/unchecked-checkbox.png) |

### Further suggested test coverage:

| Functionality         | Scenarios                   | 
|-----------------------|-----------------------------|
| Recover login details | Forgotten Password Recovery |
| Registration          | Create an account                        |  
|                       | Create an account with duplicate details |
| Access Authorisation & Portal Customisation  | Display of Dashboard Sections & Resources based on:
| | - User Role (Club Manager, Assistant Coach, Player etc) |
| | - Asset Assignments (Federation, League, Club etc) |
| | - Permissions |
| Non-functional requirements for Authn & Authz (as relevant) | Client-side: Performance (such as lighthouse), Compatibility (browser/device/mobile-first) and Accessibility tests |
| | Server-side: Performance, Stress, Soak, Scalability, Geo-scalability and/or Chaos testing |

## Design Notes

Start-small approach is used aspired by principles of [YAGNI](https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it) and [AHA!](https://kentcdodds.com/blog/aha-programming)

Domain specific dimensions and patterns may emerge as we go, and need to be accounted for on when/if basis.

For example, the following can be anticipated:

- cross environment configurations
- cross platform testing (browser/OS/device)
- more rigorous parallelisation/sharding
- user sessions clash management (in parallel or coinciding test runs)
- higher level of UI abstraction (eg screenplay pattern, Playwright page fixtures such as user role specific)
- discuss to remove `data-qa-id` from Production via build tools (for engineering best practices/PR and security considerations)
- test data management approaches (stubbing/mocking for client-side logic tests or against 3rd party services, data seeding/tidyup for full e2e tests, etc), data abstraction layer, api steps library, etc
